{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from resnet_yolo import resnet50\n",
    "from dataset import VocDetectorDataset\n",
    "from eval_voc import evaluate\n",
    "from predict import predict_image\n",
    "from config import VOC_CLASSES, COLORS\n",
    "from kaggle_submission import output_submission_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6961.5771)\n",
      "torch.Size([6974, 1])\n"
     ]
    }
   ],
   "source": [
    "S = 14\n",
    "N = 24\n",
    "B = 2\n",
    "Classes = 20\n",
    "bounding = 5\n",
    "\n",
    "# pred_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "# target_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "\n",
    "pred_tensor = torch.randn(N, S, S, B*bounding + Classes)\n",
    "target_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "\n",
    "contains_object_mask = (target_tensor[:,:,:,4] > 0) | (target_tensor[:,:,:,9] > 0)\n",
    "no_object_mask = (target_tensor[:,:,:,4] == 0)   &  (target_tensor[:,:,:,9] == 0)\n",
    "\n",
    "no_object_prediction = pred_tensor[no_object_mask].unsqueeze(-1).view(-1,30)\n",
    "no_object_target = target_tensor[no_object_mask].unsqueeze(-1).view(-1,30)\n",
    "\n",
    "indices = torch.tensor([4,9])\n",
    "no_object_prediction_confidences = torch.index_select(no_object_prediction, 1, indices)\n",
    "no_object_target_confidences = torch.index_select(no_object_target, 1, indices)\n",
    "\n",
    "no_object_prediction_mask = (no_object_prediction_confidences[:,0] > 0) | (no_object_prediction_confidences[:,1] > 0)\n",
    "no_object_prediction_mask = no_object_prediction_mask.unsqueeze(-1).expand_as(no_object_prediction_confidences)\n",
    "\n",
    "positive_prediction_confidences = no_object_prediction_confidences[no_object_prediction_mask]\n",
    "\n",
    "# We create the confidences mask, then mask to create the positive prediction confidences\n",
    "positive_prediction_confidences_on_pred = no_object_prediction_confidences[no_object_prediction_mask]\n",
    "positive_prediction_confidences_on_target = no_object_target_confidences[no_object_prediction_mask]\n",
    "\n",
    "no_object_loss = torch.sum(torch.pow(positive_prediction_confidences_on_pred - positive_prediction_confidences_on_target, 2))\n",
    "\n",
    "print(no_object_loss)\n",
    "print(positive_prediction_confidences.unsqueeze(-1).size())\n",
    "\n",
    "# import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):                                                                                                                                                             \n",
    "    '''Compute the intersection over union of two set of boxes, each box is [x1,y1,x2,y2].\n",
    "    Args:\n",
    "      box1: (tensor) bounding boxes, sized [N,4].\n",
    "      box2: (tensor) bounding boxes, sized [M,4].\n",
    "    Return:\n",
    "      (tensor) iou, sized [N,M].\n",
    "    '''\n",
    "    N = box1.size(0)\n",
    "    M = box2.size(0)\n",
    "\n",
    "    lt = torch.max(\n",
    "        box1[:,:2].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "        box2[:,:2].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "    )   \n",
    "\n",
    "    rb = torch.min(\n",
    "        box1[:,2:].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "        box2[:,2:].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "    )   \n",
    "\n",
    "    wh = rb - lt  # [N,M,2]\n",
    "    wh[wh<0] = 0  # clip at 0\n",
    "    inter = wh[:,:,0] * wh[:,:,1]  # [N,M]\n",
    "\n",
    "    area1 = (box1[:,2]-box1[:,0]) * (box1[:,3]-box1[:,1])  # [N,]\n",
    "    area2 = (box2[:,2]-box2[:,0]) * (box2[:,3]-box2[:,1])  # [M,]\n",
    "    area1 = area1.unsqueeze(1).expand_as(inter)  # [N,] -> [N,1] -> [N,M]\n",
    "    area2 = area2.unsqueeze(0).expand_as(inter)  # [M,] -> [1,M] -> [N,M]\n",
    "\n",
    "    iou = inter / (area1 + area2 - inter)\n",
    "    return iou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(357646.7500, device='cuda:0')\n",
      "tensor(357646.7500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "S = 14\n",
    "N = 24\n",
    "B = 2\n",
    "Classes = 20\n",
    "bounding = 5\n",
    "\n",
    "mseloss = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# pred_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "# target_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "last_dim_size = 30\n",
    "\n",
    "pred_tensor = torch.randn(N, S, S, B*bounding + Classes)\n",
    "target_tensor = torch.randn(N, S, S, B*bounding + Classes)\n",
    "\n",
    "contains_object_mask = (target_tensor[:,:,:,4] > 0) | (target_tensor[:,:,:,9] > 0)\n",
    "contains_object_pred = pred_tensor[contains_object_mask].view(-1, last_dim_size)\n",
    "contains_object_target = target_tensor[contains_object_mask].view(-1, last_dim_size)\n",
    "\n",
    "no_object_mask = (target_tensor[:,:,:,4] == 0)   &  (target_tensor[:,:,:,9] == 0)\n",
    "no_object_prediction = pred_tensor[no_object_mask].unsqueeze(-1).view(-1,30)\n",
    "no_object_target = target_tensor[no_object_mask].unsqueeze(-1).view(-1,30)\n",
    "\n",
    "bounding_box_pred = contains_object_pred[:,:5*B]\n",
    "# And the remainder is classes_pred\n",
    "classes_pred = contains_object_pred[:,5*B:]\n",
    "\n",
    "# 5 * B because size(batchsize,S,S,Bx5+20=30), last dimension size is Bx5+20. We want the Bx5 elements only.\n",
    "bounding_box_target = contains_object_target[:,:5*B]\n",
    "# And the remainder is classes_target\n",
    "classes_target = contains_object_target[:,5*B:]\n",
    "\n",
    "\n",
    "# print(bounding_box_target.view(-1,5))\n",
    "\n",
    "\n",
    "# Bounding box stuff:\n",
    "bounding_box_target = bounding_box_target.contiguous().to('cuda').view(-1,5)\n",
    "bounding_box_pred = bounding_box_pred.contiguous().to('cuda').view(-1,5)\n",
    "# Arbitrarily pick 3 to view\n",
    "# box_target = bounding_box_target[:1000,:]\n",
    "# box_pred = bounding_box_pred[:1000,:]\n",
    "box_target = bounding_box_target\n",
    "box_pred = bounding_box_pred\n",
    "\n",
    "\n",
    "box_target_processed = torch.zeros(box_target.size())\n",
    "box_target_processed[:,0] = box_target[:,0]/S - (0.5*box_target[:,2])\n",
    "box_target_processed[:,1] = box_target[:,1]/S - (0.5*box_target[:,3])\n",
    "box_target_processed[:,2] = box_target[:,0]/S + (0.5*box_target[:,2])\n",
    "box_target_processed[:,3] = box_target[:,1]/S + (0.5*box_target[:,3]) \n",
    "\n",
    "\n",
    "# Remove that last element (c) in last dimension, we don't need it\n",
    "box_target_processed = box_target_processed[:,:-1]\n",
    "# print(box_target_processed.shape)\n",
    "# Pre-process box prediction\n",
    "box_pred_processed = torch.zeros(box_pred.size())\n",
    "box_pred_processed[:,0] = box_pred[:,0]/S - (0.5*box_pred[:,2])\n",
    "box_pred_processed[:,1] = box_pred[:,1]/S - (0.5*box_pred[:,3])\n",
    "box_pred_processed[:,2] = box_pred[:,0]/S + (0.5*box_pred[:,2])\n",
    "box_pred_processed[:,3] = box_pred[:,1]/S + (0.5*box_pred[:,3])       \n",
    "\n",
    "# Remove the last element (c) in last dimension, we don't need it\n",
    "box_pred_processed = box_pred_processed[:,:-1]\n",
    "\n",
    "contains_object_response_mask = torch.BoolTensor(box_target.size()).fill_(False)\n",
    "box_target_iou = torch.zeros(box_target.size()).to('cuda') \n",
    "# print(box_target_processed.size()[0])\n",
    "for i in range(0,box_target_processed.size()[0], B):\n",
    "#     print(box_pred_processed[i:i+B,:].shape)\n",
    "#     print(box_target_processed[i,:].unsqueeze(0).shape)\n",
    "    iou = compute_iou(box_pred_processed[i:i+B,:], box_target_processed[i,:].unsqueeze(0))\n",
    "    max_val, max_index = iou.max(0)\n",
    "    max_index = max_index.data.to('cuda')\n",
    "    contains_object_response_mask[i+max_index] = True # Broadcast 1 into all the 5 elems of chosen row\n",
    "    box_target_iou[i+max_index, 4] = 10\n",
    "\n",
    "box_prediction_response = bounding_box_pred[contains_object_response_mask].view(-1,5)\n",
    "box_target_response = bounding_box_target[contains_object_response_mask].view(-1,5)\n",
    "box_target_response_iou = box_target_iou[contains_object_response_mask].view(-1,5)\n",
    "\n",
    "# print(box_prediction_response.view(-1,5))\n",
    "# print(box_prediction_response)\n",
    "# print(box_target_response_iou)\n",
    "contain_loss = torch.sum(torch.pow(box_prediction_response[:,4] - box_target_response_iou[:,4], 2))\n",
    "print(contain_loss)\n",
    "print(mseloss(box_prediction_response[:,4],box_target_response_iou[:,4]))\n",
    "# print(box_target_iou)\n",
    "# print(contains_object_response_mask)\n",
    "# print(box_target_response_iou)\n",
    "# print(box_target_response_iou.view(-1,5))\n",
    "\n",
    "# print(box_iou)\n",
    "# print(box_iou.shape)\n",
    "# print(box_target_processed.size())\n",
    "# print(box_target)\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(box_target_processed)\n",
    "\n",
    "\n",
    "# print(bounding_box_pred.size())\n",
    "\n",
    "# bounding boxes in cells from target that we known contain an object\n",
    "# bounding boxes in cells from prediction that we know contain an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(321088.4688)\n"
     ]
    }
   ],
   "source": [
    "classes_pred = torch.randn(14,24,24,20)\n",
    "classes_target = torch.randn(14,24,24,20)\n",
    "\n",
    "per_cell_loss = torch.sum(torch.pow(classes_pred - classes_target, 2))\n",
    "\n",
    "print(per_cell_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-33-2208b855d186>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-2208b855d186>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    pred_cls, pred_response, pred_bboxes = pred\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#print(target)\n",
    "S = 14\n",
    "N = 24\n",
    "B = 2\n",
    "Classes = 20\n",
    "bounding = 5\n",
    "\n",
    "# pred_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "# target_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "\n",
    "pred_tensor = torch.randn(N, S, S, B*bounding + Classes)\n",
    "target_tensor = torch.zeros(N, S, S, B*bounding + Classes)\n",
    "pred = pred_tensor\n",
    "target = target_tensor\n",
    "\n",
    "pred_cls, pred_response, pred_bboxes = pred\n",
    "label_cls, label_response, label_bboxes = target\n",
    "\n",
    "\n",
    "pred_cls = pred_cls\n",
    "pred_response =  pred_response\n",
    "pred_bboxes = pred_bboxes\n",
    "\n",
    "label_cls = label_cls\n",
    "label_response =  label_response\n",
    "label_bboxes = label_bboxes\n",
    "\n",
    "\n",
    "\n",
    "batch_size = pred_response.size(0)\n",
    "\n",
    "no_obj_mask = (label_response[:, :, :, 0] < 1).unsqueeze(-1).expand_as(label_response)\n",
    "\n",
    "obj_response_mask = (label_response[:, :, :, 0] > 0).unsqueeze(-1).expand_as(label_response)\n",
    "\n",
    "obj_box_mask = (label_response[:, :, :, 0] > 0).unsqueeze(-1).expand_as(label_bboxes)\n",
    "\n",
    "obj_cls_mask = (label_response[:, :, :, 0] > 0).unsqueeze(-1).expand_as(label_cls)\n",
    "\n",
    "no_obj_contain_pred = pred_response[no_obj_mask].view(-1)\n",
    "no_obj_contain_target = label_response[no_obj_mask].view(-1)\n",
    "\n",
    "\n",
    "obj_contain_pred = pred_response[obj_response_mask].view(-1, B)\n",
    "\n",
    "obj_contain_target = label_response[obj_response_mask].view(-1, B)\n",
    "\n",
    "# class pred response\n",
    "obj_class_pred = pred_cls[obj_cls_mask].view(-1, 20)\n",
    "obj_class_target = label_cls[obj_cls_mask].view(-1, 20)\n",
    "\n",
    "# box pred response\n",
    "obj_loc_pred = pred_bboxes[obj_box_mask].view(-1, B * 4)\n",
    "obj_loc_target = label_bboxes[obj_box_mask].view(-1, B * 4)\n",
    "\n",
    "iou = torch.zeros(obj_loc_pred.size(0), B)\n",
    "iou = Variable(iou)\n",
    "\n",
    "for j in range(B):\n",
    "    pred_bb = torch.zeros(obj_loc_pred.size(0), 4)\n",
    "    pred_bb = Variable(pred_bb)\n",
    "\n",
    "    target_bb = torch.zeros(obj_loc_pred.size(0), 4)\n",
    "    target_bb = Variable(target_bb)\n",
    "\n",
    "    target_bb[:, 0] = obj_loc_target[:, j * 4] - 0.5 * pow(obj_loc_target[:, j * 4 + 2], 2)\n",
    "    target_bb[:, 1] = obj_loc_target[:, j * 4 + 1] - 0.5 * pow(obj_loc_target[:, j * 4 + 3], 2)\n",
    "    target_bb[:, 2] = obj_loc_target[:, j * 4] + 0.5 * pow(obj_loc_target[:, j * 4 + 2], 2)\n",
    "    target_bb[:, 3] = obj_loc_target[:, j * 4 + 1] + 0.5 * pow(obj_loc_target[:, j * 4 + 3], 2)\n",
    "\n",
    "    pred_bb[:, 0] = obj_loc_pred[:, j * 4] - 0.5 * pow(obj_loc_pred[:, j * 4 + 2], 2)\n",
    "    pred_bb[:, 1] = obj_loc_pred[:, j * 4 + 1] - 0.5 * pow(obj_loc_pred[:, j * 4 + 3], 2)\n",
    "    pred_bb[:, 2] = obj_loc_pred[:, j * 4] + 0.5 * pow(obj_loc_pred[:, j * 4 + 2], 2)\n",
    "    pred_bb[:, 3] = obj_loc_pred[:, j * 4 + 1] + 0.5 * pow(obj_loc_pred[:, j * 4 + 3], 2)\n",
    "\n",
    "    iou[:, j] = self.compute_iou(target_bb, pred_bb)\n",
    "\n",
    "max_iou, max_index = iou.max(1)\n",
    "min_iou, _ = iou.min(1)\n",
    "max_index = max_index.data.cpu()\n",
    "\n",
    "coo_response_mask = torch.ByteTensor(obj_loc_pred.size(0), B * 4)\n",
    "\n",
    "coo_response_mask.zero_()\n",
    "for i in range(obj_loc_pred.size(0)):\n",
    "    coo_response_mask[i, max_index[i] * 4:max_index[i] * 4 + 4] = 1\n",
    "\n",
    "obj_axis_pred = obj_loc_pred[coo_response_mask].view(-1, 4)\n",
    "obj_axis_target = obj_loc_target[coo_response_mask].view(-1, 4)\n",
    "\n",
    "iou_response_mask = coo_response_mask[:, [i * 4 for i in range(B)]]\n",
    "\n",
    "obj_response_pred = obj_contain_pred[iou_response_mask].view(-1)\n",
    "obj_response_target = obj_contain_target[iou_response_mask].view(-1)\n",
    "\n",
    "obj_local_loss = F.mse_loss(obj_axis_pred[:, 0:2], obj_axis_target[:, 0:2], size_average=False) + \\\n",
    "                 F.mse_loss(obj_axis_pred[:, 2:4], obj_axis_target[:, 2:4], size_average=False)\n",
    "obj_class_loss = F.mse_loss(obj_class_pred, obj_class_target, size_average=False)\n",
    "\n",
    "\n",
    "max_iou = (max_iou.data)\n",
    "conf_id = ((1 - max_iou) * self.l_noobj + max_iou)\n",
    "\n",
    "conf_id = Variable(conf_id, requires_grad=True)\n",
    "\n",
    "obj_contain_loss = F.mse_loss(obj_response_pred, max_iou, size_average=False)\n",
    "\n",
    "no_obj_contain_loss = F.mse_loss(no_obj_contain_pred, no_obj_contain_target, size_average=False)\n",
    "\n",
    "iou_loss = F.mse_loss(max_iou, obj_response_target, size_average=False)\n",
    "\n",
    "loss_all = (self.l_coord * obj_local_loss + obj_class_loss + obj_contain_loss + self.l_noobj * no_obj_contain_loss + iou_loss) / batch_size\n",
    "\n",
    "loss_info = {\n",
    "    'local_loss': self.l_coord * obj_local_loss.data,\n",
    "    'class_loss': obj_class_loss.data,\n",
    "    'contain_loss': obj_contain_loss.data,\n",
    "    'no_contain_loss': self.l_noobj * no_obj_contain_loss,\n",
    "    'iou_loss': iou_loss,\n",
    "    'mean_iou': torch.mean(max_iou)\n",
    "}\n",
    "\n",
    "return loss_all, loss_info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
